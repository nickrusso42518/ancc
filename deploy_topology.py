#!/usr/bin/env python

"""
Author: Nick Russo
Purpose: Tests Batfish on sample Cisco Live sessions focused
on the OSPF routing protocol using archived configurations.
"""

import json
import re
import httpx

# TODO junos?
OS_TATTR_MAP = {
    "CISCO_IOS": {"tmpl_name": "L3IOU-15.6.3"},
    # "JUNOS": {"tmpl_name": "VMX"}
    "nonbf-gns3-ethsw": {"tmpl_name": "Ethernet switch"},
}


def main(base_url, snapshot_name):
    """
    Execution starts here.
    """

    # Load the topology generated by the Batfish testing
    in_dir = f"outputs/{snapshot_name}"
    with open(f"{in_dir}/bf_topology.json", "r", encoding="utf-8") as handle:
        topology = json.load(handle)

    # Remove unidirectional links from the topology. eg: R01-R02 and
    # R02-R01 may exist, but we only need one pair for GNS3 specifically.
    # Use a set to filter out duplicate 2-tuples (immutable) after
    # converting each hostname/interface pair to "batfish" string format.
    unique_links = set()
    for link in topology["all_links"]:
        intfs = [
            f"[{intf['hostname']}]{intf['interface']}" for intf in link.values()
        ]
        unique_links.add(tuple(sorted(intfs)))

    # Sanity check; unique links must be half as big as the full topology
    assert len(topology["all_links"]) == len(unique_links) * 2

    with httpx.Client() as client:
        # Get compute nodes and find the GNS3 VM
        """
        for comp in _req(client, method="get", url=f"{base_url}/computes").json():
            if comp["name"].startswith("GNS3 VM"):
                print("GNS3 VM comp_id:", comp_id := comp["compute_id"])
                break
        else:
            raise ValueError("GNS3 VM compute not found")
        """

        # Loop over all templates and expected OS attrs, then populate those
        # OS attrs with the template ID as they are discovered
        templates = _req(client, method="get", url=f"{base_url}/templates").json()
        for tattr in OS_TATTR_MAP.values():
            for tmpl in templates:
                if tmpl["name"] == tattr["tmpl_name"]:
                    tattr["tmpl_id"] = tmpl["template_id"]
                    print(f"{tmpl['name']} tmpl_id: {tattr['tmpl_id']}")
                    break
            else:
                raise ValueError(f"{tattr['tmpl_name']} template not found")

        # Create a new project and store the UUID
        proj_id = _req(
            client=client,
            method="post",
            url=f"{base_url}/projects",
            json={"name": f"ancc_{snapshot_name}"},
        ).json()["project_id"]

        # Iterate over the unique nodes, deploying each based on the
        # template. Certain parameters can be overridden/customized.
        # Update each node dict with the desired GNS3 template name (by OS)
        node_ids = {}
        for i, (node, attr) in enumerate(topology["nodes"].items()):
            attr |= {"tmpl_name": OS_TATTR_MAP[attr["Configuration_Format"]]}

            # Compute (x,y) coordinates for node, creating horizonal rows of 4
            # Example placement whereby 1 is at (0,0):
            # 5 6 7 8
            # 1 2 3 4
            x, y = (i * 100 % 400, i // 4 * 100)

            # Generate the GNS3 POST payload to add a node from a template.
            # Not that some fields cannot be specified, such as "console" port
            node_body = {
                "name": node,
                "x": x,
                "y": y,
                # "compute_id": comp_id,
            }

            # Based on the config format, get the template ID
            os_type = attr["Configuration_Format"]
            tmpl_id = OS_TATTR_MAP[os_type]["tmpl_id"]

            # Deploy the node from the proper template, which varies by OS
            depl = _req(
                client=client,
                method="post",
                url=f"{base_url}/projects/{proj_id}/templates/{tmpl_id}",
                json=node_body,
            ).json()

            # Print the node's location and access information
            print(
                f"Adding {node} at ({x},{y}) on port {depl['console']}"
                f"with id {depl['node_id']}"
            )

            # TODO different method per device type
            if os_type == "CISCO_IOS":
                # Upload the startup configs from the Batfish snapshot
                with open(
                    f"snapshots/pre/configs/{node.upper()}.txt",
                    "r",
                    encoding="utf-8",
                ) as handle:
                    config_text = handle.read()

                # Upload startup config; reponse has no body, ignore it
                _req(
                    client=client,
                    method="post",
                    url=f"{base_url}/projects/{proj_id}/nodes/{depl['node_id']}/files/startup-config.cfg",
                    data=config_text,
                )
                print(f"Uploaded startup-cfg for {os_type} node: {node}")
            else:
                print(f"No startup-cfg method for {os_type} node: {node}")

            # Retain deployment response IDs to add links later
            node_ids[node] = depl["node_id"]

        # Now, make the API calls to create the links between node pairs
        for link in unique_links:
            a_data, b_data = _parse_intf(link[0]), _parse_intf(link[1])

            # Construct the HTTP body for the API call, specifying the
            # node ID (response from node creation), plus the adapter/port
            # number to be connected (convert to int first)
            link_body = {
                "nodes": [
                    {
                        "node_id": node_ids[a_data["node"]],
                        "adapter_number": int(a_data["adapter"]),
                        "port_number": int(a_data["port"]),
                    },
                    {
                        "node_id": node_ids[b_data["node"]],
                        "adapter_number": int(b_data["adapter"]),
                        "port_number": int(b_data["port"]),
                    },
                ]
            }

            # Send a POST request to connect the A and B nodes, response
            # is JSON and contains a link_id, but we don't care
            conn = _req(
                client=client,
                method="post",
                url=f"{base_url}/projects/{proj_id}/links",
                json=link_body,
            ).json()

            # Print the link's interconnected members and ID
            print(
                f"Connected {a_data['node']}-{a_data['node']} with id {conn['link_id']}"
            )

        # Nodes and links done; start all nodes (no response)
        _req(
            client=client,
            method="post",
            url=f"{base_url}/projects/{proj_id}/nodes/start",
            json={},
        )


def _parse_intf(intf_str):
    regex = re.compile(
        r"^\[(?P<node>\S+)\][A-Za-z]*(?P<adapter>\d+)/(?P<port>\d+)$"
    )
    return re.search(regex, intf_str).groupdict()


def _req(client, method, **kwargs):
    """
    Issue an HTTP request using the supplied parameters, perform
    error checking to ensure status code is less than 400, then
    return the JSON structured data from the message body.
    """
    resp = client.request(method=method, **kwargs)
    resp.raise_for_status()
    return resp


if __name__ == "__main__":
    # Can target GNS3 http://local:3080 or http://VM:80
    main("http://192.168.120.128/v2", "pre")
